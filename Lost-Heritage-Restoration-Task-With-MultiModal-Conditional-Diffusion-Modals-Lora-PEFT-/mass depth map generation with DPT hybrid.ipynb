{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dafd9c-df0b-4ac6-b5b3-4e76c30aa874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# **Depth Map Generator with Progress Monitoring**\n",
    "* Real-time progress tracking for every batch  \n",
    "* GPU memory monitoring  \n",
    "* Error handling with retries\n",
    "\"\"\"\n",
    "# %%\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import humanize\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import torch.utils.data\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## **1. Enhanced Progress Tracker**\n",
    "\"\"\"\n",
    "# %%\n",
    "class ProgressTracker:\n",
    "    def __init__(self, total_images):\n",
    "        self.start_time = time.time()\n",
    "        self.total_images = total_images\n",
    "        self.completed = 0\n",
    "        self.failed = 0\n",
    "        self.last_update = 0\n",
    "        \n",
    "    def update(self, batch_size, failed=0):\n",
    "        self.completed += batch_size - failed\n",
    "        self.failed += failed\n",
    "        \n",
    "        # Update stats every 2 seconds\n",
    "        if time.time() - self.last_update > 2 or self.completed == self.total_images:\n",
    "            self._print_stats()\n",
    "            self.last_update = time.time()\n",
    "    \n",
    "    def _print_stats(self):\n",
    "        elapsed = time.time() - self.start_time\n",
    "        speed = self.completed / max(elapsed, 1e-6)\n",
    "        remaining = (self.total_images - self.completed) / max(speed, 1e-6)\n",
    "        \n",
    "        # GPU memory stats\n",
    "        gpu_mem = humanize.naturalsize(torch.cuda.memory_allocated())\n",
    "        gpu_max = humanize.naturalsize(torch.cuda.max_memory_allocated())\n",
    "        \n",
    "        print(\n",
    "            f\"\\nüìä Progress: {self.completed}/{self.total_images} \"\n",
    "            f\"({self.completed/self.total_images:.1%}) | \"\n",
    "            f\"Speed: {speed:.1f} img/s | \"\n",
    "            f\"ETA: {remaining:.0f}s\\n\"\n",
    "            f\"üíæ GPU Mem: {gpu_mem} (Peak: {gpu_max}) | \"\n",
    "            f\"Failures: {self.failed}\"\n",
    "        )\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## **2. Enhanced Depth Generator**\n",
    "\"\"\"\n",
    "# %%\n",
    "def generate_depth_maps(input_folder, output_folder, batch_size=16, max_retries=2):\n",
    "    input_folder = Path(input_folder)\n",
    "    output_folder = Path(output_folder)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_paths = []\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp']:\n",
    "        image_paths.extend(list(input_folder.rglob(ext)))\n",
    "    total_images = len(image_paths)\n",
    "    \n",
    "    # Initialize tracker\n",
    "    tracker = ProgressTracker(total_images)\n",
    "    print(f\"üéØ Starting processing of {total_images} images in batches of {batch_size}\")\n",
    "    \n",
    "    # Dataloader with error handling\n",
    "    class SafeDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, paths):\n",
    "            self.paths = paths\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            for _ in range(max_retries):\n",
    "                try:\n",
    "                    img = cv2.imread(str(self.paths[idx]))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    return torch.from_numpy(img).permute(2,0,1).float() / 255.0, str(self.paths[idx])\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error reading {self.paths[idx]}: {str(e)}\")\n",
    "                    time.sleep(1)\n",
    "            return None, None\n",
    "    \n",
    "    dataset = SafeDataset(image_paths)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        collate_fn=lambda x: [item for item in x if item[0] is not None]\n",
    "    )\n",
    "    \n",
    "    # Processing loop\n",
    "    with torch.inference_mode(), torch.cuda.amp.autocast():\n",
    "        for batch in tqdm(loader, desc=\"Total progress\", unit=\"batch\"):\n",
    "            try:\n",
    "                # Move data to GPU\n",
    "                images = [item[0] for item in batch]\n",
    "                paths = [item[1] for item in batch]\n",
    "                batch_tensor = torch.stack(images).to('cuda').half()\n",
    "                \n",
    "                # Predict depth\n",
    "                depth_outputs = model(batch_tensor)\n",
    "                \n",
    "                # Save results\n",
    "                failed_in_batch = 0\n",
    "                for i, depth in enumerate(depth_outputs):\n",
    "                    try:\n",
    "                        depth_map = process_depth(depth)\n",
    "                        rel_path = Path(paths[i]).relative_to(input_folder)\n",
    "                        save_path = output_folder / rel_path.with_suffix('.png')\n",
    "                        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                        cv2.imwrite(str(save_path), depth_map)\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Failed to save {paths[i]}: {str(e)}\")\n",
    "                        failed_in_batch += 1\n",
    "                \n",
    "                # Update progress\n",
    "                tracker.update(len(batch), failed_in_batch)\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                if 'CUDA out of memory' in str(e):\n",
    "                    print(\"üí• OOM detected, reducing batch size...\")\n",
    "                    batch_size = max(1, batch_size // 2)\n",
    "                    loader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=2\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Batch failed: {str(e)}\")\n",
    "                    tracker.update(len(batch), len(batch))\n",
    "    \n",
    "    print(f\"\\n‚úÖ Completed! Processed {tracker.completed} images\")\n",
    "    print(f\"   Failures: {tracker.failed}\")\n",
    "    print(f\"   Peak GPU memory: {humanize.naturalsize(torch.cuda.max_memory_allocated())}\")\n",
    "    print(f\"   Total time: {time.time() - tracker.start_time:.1f}s\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## **3. Run with Full Monitoring**\n",
    "\"\"\"\n",
    "# %%\n",
    "# Configuration\n",
    "INPUT_ROOT = \"/content/input\"\n",
    "OUTPUT_ROOT = \"/content/depth_maps\"\n",
    "BATCH_SIZE = 32  # Start high, auto-reduces on OOM\n",
    "\n",
    "# Initialize model\n",
    "model = torch.hub.load('intel-isl/MiDaS', 'DPT_Large').eval().half().to('cuda')\n",
    "\n",
    "# Start processing\n",
    "generate_depth_maps(INPUT_ROOT, OUTPUT_ROOT, batch_size=BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
